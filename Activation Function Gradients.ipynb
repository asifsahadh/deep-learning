{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e13199c-fdc2-4d5e-b73d-11fec50a633c",
   "metadata": {},
   "source": [
    "## Activation Functions and their Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b8795-cc81-4831-b740-cd64ee42c3d4",
   "metadata": {},
   "source": [
    "Neural networks are trained using gradient-based optimization algorithms, such as stochastic gradient descent (SGD). The gradients of the activation functions are crucial for backpropagation, the algorithm used to compute gradients for the network's weights.\n",
    "\n",
    "In this notebook, classes for several activation functions and their gradients are coded. These functions include Sigmoid, Tanh, Linear, ReLU, Leaky ReLU & ELU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d8d7c-77bc-44e9-80a5-512901eb0db8",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b8c630-76a8-4608-a734-eef1d3fd3223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return 1.0/1.0 + np.exp(-X)\n",
    "\n",
    "    def gradient(self, X):\n",
    "        Q = self(X)\n",
    "        return Q * (1-Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded2fe98-db0a-49b0-9a95-88001bd07399",
   "metadata": {},
   "source": [
    "### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd908b1a-7c29-40ab-94d4-d119ad884a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def gradient(self, X):\n",
    "        return 1 - np.tanh(X)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5560f-c54b-433f-b260-b7d2be7675fa",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40067626-b7ec-4963-b516-af134ed6df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return X\n",
    "\n",
    "    def gradient(self, X):\n",
    "        return np.ones(X.shape, dtype = float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27e335-d8ec-4b1e-90d9-7ec147684c27",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e17404b-dd03-4f5e-b849-f6a96df10fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, X):\n",
    "        Y = np.zeros(X.shape, dtype = float)\n",
    "        Y[X > 0] = X[X > 0]\n",
    "        return Y\n",
    "\n",
    "    def gradient(self, X):\n",
    "        Y = self(X)\n",
    "        Y[Y >= 0] = 1\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3658a-c83c-4128-9f67-6159f03d3245",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f6d8ce0-61a8-4eea-8d9d-d6ab4bd75d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyReLU(object):\n",
    "    def __init__(self, alpha = 0.01):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, X):\n",
    "        Y = np.array(X, dtype = float)\n",
    "        Y[Y < 0] *= self.alpha\n",
    "        return Y\n",
    "\n",
    "    def gradient(self, X):\n",
    "        Y = np.array(X, dtype = float)\n",
    "        Y[Y >= 0] = 1\n",
    "        Y[Y < 0] = self.alpha\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb0290-f96e-4fd9-9cae-3918e37149ba",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3d7bfe2-14c7-4e25-8d15-ace3f5a21cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELU(object):\n",
    "    def __init__(self, alpha = 0.01):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, X):\n",
    "        Y = np.array(X, dtype = float)\n",
    "        Y[Y < 0] = self.alpha * np.exp(Y[Y < 0] - 1)\n",
    "        return Y\n",
    "\n",
    "    def gradient(self, X):\n",
    "        Y = np.array(X, dtype = float)\n",
    "        Y[Y >= 0] = 1\n",
    "        Y[Y < 0] = self.alpha * np.exp(Y[Y < 0])\n",
    "        return Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
